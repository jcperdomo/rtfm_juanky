{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279ac4ee-a5bf-40b5-9f2a-2c536a1326a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional setup; use if the notebook is not running inside the rtfm conda environment\n",
    "!git clone https://github.com/mlfoundations/rtfm.git\n",
    "%cd rtfm\n",
    "\n",
    "# Ensure pip is up to date\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Install Python 3.8 using pip\n",
    "!pip install python==3.8\n",
    "\n",
    "# Install pip dependencies from requirements.txt\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Install additional dependencies\n",
    "!pip install git+https://github.com/jpgard/llama-recipes.git\n",
    "!pip install -e .\n",
    "!pip install --no-deps git+https://github.com/mlfoundations/tableshift.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae8598ee797839f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Inference with TabuLa-8B\n",
    "\n",
    "This notebook shows some example workflows of how to perform inference with TabuLa-8B. \n",
    "\n",
    "For best performance, this notebook should be run with access to a GPU.\n",
    "\n",
    "TabuLa-8B supports inference on zero- and few-shot tabular data (with the number of shots only limited by the context window of the model) and both categorical and continuous inputs. Below, we show examples of both. \n",
    "\n",
    "TabuLa's inference uses pandas DataFrames to construct examples for downstream inference. We directly construct Pandas DataFrames below, but you can also read DataFrames from CSV files or any other source that can be converted to DataFrame.\n",
    "\n",
    "**Note about evaluation with labeled data**: If you only want to perform efficient evaluation on data that is already labeled (i.e. to assess the accuracy of TabuLa on your own dataset), we provide separate code to do this which is likely to be more performant than the code in this notebook (which is optimized for simplicity/usability, not performance). Please see the README in the main repo for instructions on how to prepare your data for evaluation with our eval pipeline. Note that that eval pipeline (not the code in this notebook) is also what was used to evaluate TabuLa-8B on our [paper](https://arxiv.org/abs/2406.12031)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14460216956d8859",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Model loading and setup\n",
    "\n",
    "First, load the model and tokenizer. It is important to use the TabuLa tokenizer (not the base Llama 3 tokenizer) due to the special tokens used for serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T20:04:12.934625Z",
     "start_time": "2024-06-28T20:03:42.468103Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM, AutoConfig\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "import random\n",
    "from rtfm.configs import TrainConfig, TokenizerConfig\n",
    "from rtfm.inference_utils import InferenceModel\n",
    "from rtfm.serialization.serializers import get_serializer\n",
    "from rtfm.tokenization.text import prepare_tokenizer\n",
    "\n",
    "train_config = TrainConfig(model_name=\"mlfoundations/tabula-8b\", context_length=8192)\n",
    "\n",
    "# If using a base llama model (not fine-tuned TabuLa),\n",
    "# make sure to set add_serializer_tokens=False\n",
    "# (because we do not want to use special tokens for \n",
    "# the base model which is not trained on them).\n",
    "tokenizer_config = TokenizerConfig()\n",
    "\n",
    "# Load the configuration\n",
    "config = AutoConfig.from_pretrained(train_config.model_name)\n",
    "\n",
    "# Set the torch_dtype to bfloat16 which matches TabuLa train/eval setup\n",
    "config.torch_dtype = 'bfloat16'\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    train_config.model_name, device_map=\"auto\", config=config).to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(train_config.model_name)\n",
    "serializer = get_serializer(train_config.serializer_cls)\n",
    "\n",
    "tokenizer, model = prepare_tokenizer(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    pretrained_model_name_or_path=train_config.model_name,\n",
    "    model_max_length=train_config.context_length,\n",
    "    use_fast_tokenizer=tokenizer_config.use_fast_tokenizer,\n",
    "    serializer_tokens_embed_fn=tokenizer_config.serializer_tokens_embed_fn,\n",
    "    serializer_tokens=serializer.special_tokens\n",
    "    if tokenizer_config.add_serializer_tokens\n",
    "    else None,\n",
    ")\n",
    "\n",
    "inference_model = InferenceModel(model=model, tokenizer=tokenizer, serializer=serializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eb7965984ae881",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Creating your own data for inference\n",
    "\n",
    "If you simply want to explore the model, or would like to construct your own data for inference, you can simply construct DataFrames to represent the labeled examples (\"shots\"), if any are used, and the target example that you want to predict on.\n",
    "\n",
    "Below is an example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, dataframe, target_colname, target_choices):\n",
    "    \"\"\"\n",
    "    computes model embeddings for examples\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        if i % 50 == 0:\n",
    "            print(i)\n",
    "        embedding = model.predict(\n",
    "            target_example=dataframe.iloc[[i]],\n",
    "            target_colname=target_colname,\n",
    "            target_choices=target_choices,\n",
    "            labeled_examples=None,\n",
    "            embed=True\n",
    "        )\n",
    "        result.append(embedding)\n",
    "    return torch.concat(result, axis=0)\n",
    "\n",
    "def select_examples(k, example_embeddings, target_embedding):\n",
    "    \"\"\"\n",
    "    selects examples according to cosine distance\n",
    "    \"\"\"\n",
    "    examples = torch.nn.functional.normalize(example_embeddings)\n",
    "    target = torch.nn.functional.normalize(target_embedding)\n",
    "    scores = torch.flatten(examples @ target.T)\n",
    "    return torch.topk(scores, k).indices.tolist()\n",
    "\n",
    "# compute accuracy with random examples\n",
    "def get_acc(df, embeddings, num_shots, use_rices, target_col, target_choices):\n",
    "    n = df.shape[0]\n",
    "    num_correct = 0\n",
    "    for i in range(n):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        available_ixs = list(range(n))\n",
    "        del available_ixs[i]\n",
    "\n",
    "        if use_rices == False:\n",
    "            selected = random.choices(available_ixs, k=num_shots)\n",
    "        else:\n",
    "            selected = select_examples(num_shots, embeddings[available_ixs], embeddings[[i]])\n",
    "\n",
    "        output = inference_model.predict(\n",
    "            target_example=df.iloc[[i]],\n",
    "            target_colname=target_col,\n",
    "            max_new_tokens=10,\n",
    "            target_choices=target_choices,\n",
    "            labeled_examples=df.iloc[selected],\n",
    "        )\n",
    "\n",
    "        true_label = df.iloc[i][target_col]\n",
    "        print(output, true_label)\n",
    "        correct = int(output == true_label)\n",
    "        num_correct += correct\n",
    "\n",
    "    return num_correct / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ce396",
   "metadata": {},
   "outputs": [],
   "source": [
    "n,d = 1000, 2\n",
    "X = np.random.randn(n,d)\n",
    "beta = np.sign(np.random.randn(d))\n",
    "y = X @ beta + .5 * np.random.randn(n)\n",
    "data_matrix =  np.concatenate([X, y.reshape(-1,1)], axis=1)\n",
    "columns = ['x0', 'x1', 'y']\n",
    "regression_df = pd.DataFrame(data=data_matrix, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sm.ols(formula=\"y ~ x0 + x1\", data=regression_df).fit()\n",
    "print(result.summary())\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016faae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"inria-soda/tabular-benchmark\", data_files=\"reg_cat/house_sales.csv\")\n",
    "dataset = dataset['train'].to_pandas().sample(frac=1).iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b8148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_continuous_column(column: pd.Series, thresholds) -> pd.Series:\n",
    "    \"\"\"Take a continuous-valued column and discretize it into num_buckets.\n",
    "\n",
    "    The formatting of the outputs is of the form 'less than 0', 'between 0.5 and 0.9', or 'greater than 1.99'\n",
    "    etc. depending on the value of the observation and the number of buckets used.\n",
    "\n",
    "    This is the same format used in training TabuLa-8B and should be used for inference and\n",
    "    evaluation of that model.\n",
    "    \"\"\"\n",
    "    assert pd.api.types.is_numeric_dtype(column)\n",
    "\n",
    "    # Compute bucket thresholds\n",
    "    # thresholds = [column.quantile(i / num_buckets) for i in range(1, num_buckets)]\n",
    "    \n",
    "\n",
    "    # Define a function to categorize each value\n",
    "    def categorize_value(x):\n",
    "        for i, threshold in enumerate(thresholds):\n",
    "            if x < threshold:\n",
    "                if i == 0:\n",
    "                    return f\"less than {threshold}\"\n",
    "                else:\n",
    "                    return f\"between {thresholds[i-1]} and {threshold}\"\n",
    "        return f\"greater than {thresholds[-1]}\"\n",
    "\n",
    "    # Apply the categorization function to the column\n",
    "    return column.apply(categorize_value)\n",
    "\n",
    "def get_regression_bucket_choices(thresholds):\n",
    "    target_choices = []\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        if i == 0:\n",
    "            target_choices.append(f\"less than {threshold}\") \n",
    "        else:\n",
    "            target_choices.append(f\"between {thresholds[i-1]} and {threshold}\")\n",
    "    target_choices.append(f\"greater than {thresholds[-1]}\")\n",
    "    return target_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690505ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_regression_bucket_choices([.333, .66, .888])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress_example(model, df, target_col, target_ix, shots_ixs, lower_bound, upper_bound, num_buckets, tol=.01):\n",
    "\n",
    "    while upper_bound - lower_bound >  tol:\n",
    "        \"\"\"\n",
    "        this logic is a bit confusing, but the following example helps\n",
    "        say the bound in [0,1] and you have 3 buckets\n",
    "        you want to do\n",
    "        less than .333, betweeen .333 and .666, and greater than .666\n",
    "        so len(thresholds) = num_buckets - 1\n",
    "        and the thresholds are always strictly between the upper and lower bounds\n",
    "        \"\"\"\n",
    "        thresholds = np.linspace(lower_bound, upper_bound, num_buckets + 1)[1:-1].round(4)\n",
    "\n",
    "        curr_df = df.copy()\n",
    "\n",
    "        curr_df[target_col] = discretize_continuous_column(curr_df[target_col], thresholds)\n",
    "        target_choices = get_regression_bucket_choices(thresholds)\n",
    "\n",
    "        output = model.predict(\n",
    "            target_example = curr_df.iloc[[target_ix]],\n",
    "            target_colname = target_col,\n",
    "            target_choices = target_choices,\n",
    "            max_new_tokens = 50,\n",
    "            labeled_examples = curr_df.iloc[shots_ixs],\n",
    "        )\n",
    "        print(lower_bound, upper_bound)\n",
    "        print(thresholds)\n",
    "        print(target_choices)\n",
    "        print(output)\n",
    "        print(\"------- \\n\")\n",
    "\n",
    "        num_thresholds = len(target_choices) \n",
    "\n",
    "        i = target_choices.index(output) # returns index of matching output, Value error if not\n",
    "\n",
    "        if i == 0:\n",
    "            upper_bound = thresholds[0]\n",
    "        elif i > 0 and i == num_thresholds - 1:\n",
    "            lower_bound = thresholds[-1]\n",
    "        else:\n",
    "            lower_bound = thresholds[i-1]\n",
    "            upper_bound = thresholds[i]\n",
    "\n",
    "    return (upper_bound + lower_bound) / 2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fdef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_digits = 2\n",
    "df = dataset.round(4)\n",
    "TARGET_COL = df.columns[-1]\n",
    "N = 50\n",
    "num_shots = 32\n",
    "init_a = df[TARGET_COL].min()\n",
    "init_b = df[TARGET_COL].max()\n",
    "num_buckets = 3\n",
    "TARGET_COL, init_a, init_b, num_buckets\n",
    "range_shots = [4,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a479b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(2):\n",
    "    for num_shots in range_shots:\n",
    "        available_ixs = list(range(df.shape[0]))\n",
    "        del available_ixs[i]\n",
    "        shot_ixs = random.choices(available_ixs, k=num_shots)\n",
    "\n",
    "        pred = regress_example(inference_model, df, TARGET_COL, i, shot_ixs, \n",
    "                            init_a, init_b, num_buckets, tol=.01)\n",
    "\n",
    "\n",
    "        print(f\"true label {df.iloc[i][TARGET_COL]}, prediction {pred}\")\n",
    "        res.append((i, df.iloc[i][TARGET_COL], pred, num_shots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37cbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(res, columns=['ix', 'true_label', 'prediction', 'num_shots'])\n",
    "res_df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d013a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213433af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aaaf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(preds, df[TARGET_COL].values[:len(preds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a9bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c03c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(df[TARGET_COL].values[:len(preds)], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648264b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict example\n",
    "\n",
    "\n",
    "target_example = df.iloc[[102]]\n",
    "output = inference_model.predict(\n",
    "    target_example= target_example,\n",
    "    target_colname=TARGET_COL,\n",
    "    target_choices=TARGET_CHOICES,\n",
    "    max_new_tokens=10,\n",
    "    labeled_examples= df.iloc[[0]],\n",
    ")\n",
    "print(f\"Prediction for sample \\n {target_example} \\n is: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "df_names = ['MagicTelescope', 'covertype', 'house_16H', 'Diabetes130US', 'Higgs']  \n",
    "df_list = []\n",
    "for name in df_names:     \n",
    "    dataset = load_dataset(\"inria-soda/tabular-benchmark\", data_files=\"clf_num/{}.csv\".format(name))\n",
    "    df = dataset['train'].to_pandas().astype(str).sample(frac=1).iloc[:1000]\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7419e50-1aab-4afe-a821-5d60422e3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../multiclass_logistic.csv\").astype(str)\n",
    "# TARGET_COL = 'y'\n",
    "# TARGET_CHOICES = list(df['y'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "    TARGET_COL = df.columns[-1]\n",
    "    TARGET_CHOICES = list(df[TARGET_COL].unique())\n",
    "    # print(TARGET_COL, TARGET_CHOICES)\n",
    "    target_example = df.iloc[[102]]\n",
    "    output = inference_model.predict(\n",
    "        target_example= target_example,\n",
    "        target_colname=TARGET_COL,\n",
    "        target_choices=TARGET_CHOICES,\n",
    "        max_new_tokens=10,\n",
    "        labeled_examples= df.iloc[[0]],\n",
    "    )\n",
    "    print(f\"Prediction for sample \\n {target_example} \\n is: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(df_list):    \n",
    "    \n",
    "    TARGET_COL = df.columns[-1]\n",
    "    TARGET_CHOICES = list(df[TARGET_COL].unique())\n",
    "\n",
    "    df_embeddings = get_embeddings(inference_model, df, TARGET_COL, TARGET_CHOICES)\n",
    "    N = 1000\n",
    "    NUM_SHOTS = [2, 8]\n",
    "    # df = binary_df \n",
    "    results_df = []\n",
    "    for num_shots in NUM_SHOTS:\n",
    "        for use_rices in [True, False]:\n",
    "            acc = get_acc(df.iloc[:N], df_embeddings[:N], num_shots, use_rices, TARGET_COL, TARGET_CHOICES)\n",
    "            ci = proportion_confint(int(acc * N), N, alpha=0.05, method='beta')\n",
    "            res = {\"RICES\": use_rices, \"num_shots\": num_shots, \"acc\": acc, 'n_test': N, 'ci': ci}\n",
    "            print(res)\n",
    "            results_df.append(res)\n",
    "\n",
    "    results_df = pd.DataFrame(results_df)\n",
    "    results_df.to_csv('{}_rices_{}.csv'.format(df_names[i], N), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0b5a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe04ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100\n",
    "proportion_confint(int(.8 * n), n, alpha=0.05, method='beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d4af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
